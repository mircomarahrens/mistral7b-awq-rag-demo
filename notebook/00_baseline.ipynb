{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Retrieval-augmented generation with open-source, quantized large language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Retrieval-augmented generation (RAG) is a technique that combines the benefits of large-scale pre-trained language models (LMs) with the benefits of retrieving relevant information from a large corpus. The technique is described in the paper [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401).\n",
    "\n",
    "We will use this framework to build a chat system that will be able to answer questions providing a given context from selective data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, we need to import some libraries. [PyTorch](https://pytorch.org/) is a library for tensor computation and deep learning. We will use the torch utilities to basic interactions with our GPU. [Transformers](https://huggingface.co/docs/transformers/index) is a library for state-of-the-art NLP models. We will use it to load our model, specify the tokenizer and to use [BitsAndBytes](https://github.com/TimDettmers/bitsandbytes) to provide configurations for quantizing the model. Quantization is a technique to reduce the memory footprint of a model tremendously. This is achieved by reducing the precision of the model's weights. It allows us to use a larger model. Further details about the technique are described in the papers [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference](https://arxiv.org/abs/1712.05877) and [AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration](https://arxiv.org/abs/2306.00978)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Download model\n",
    "\n",
    "For educational reason we will use here the original, unquantized model as our starting point. The download will take some time hence we surpress the execution here and only provide the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git lfs clone https://huggingface.co/mistralai/Mistral-7B-v0.1 ../resource/model/Mistral-7B-v0.1\n",
    "# WARNING: 'git lfs clone' is deprecated and will not be updated\n",
    "#           with new flags from 'git clone'\n",
    "\n",
    "# 'git clone' has been updated in upstream Git to have comparable\n",
    "# speeds to 'git lfs clone'.\n",
    "# Cloning into '../resource/model/Mistral-7B-v0.1'...\n",
    "# remote: Enumerating objects: 79, done.\n",
    "# remote: Counting objects: 100% (75/75), done.\n",
    "# remote: Compressing objects: 100% (74/74), done.\n",
    "# remote: Total 79 (delta 39), reused 0 (delta 0), pack-reused 4\n",
    "# Unpacking objects: 100% (79/79), 470.69 KiB | 2.39 MiB/s, done.\n",
    "# Downloading LFS objects: 100% (3/3), 15 GB | 32 MB/s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../resource/model/Mistral-7B-v0.1\u001b[0m\n",
      "├── README.md\n",
      "├── config.json\n",
      "├── generation_config.json\n",
      "├── pytorch_model-00001-of-00002.bin\n",
      "├── pytorch_model-00002-of-00002.bin\n",
      "├── pytorch_model.bin.index.json\n",
      "├── special_tokens_map.json\n",
      "├── tokenizer.json\n",
      "├── tokenizer.model\n",
      "└── tokenizer_config.json\n",
      "\n",
      "0 directories, 10 files\n"
     ]
    }
   ],
   "source": [
    "!tree -L 1 ../resource/model/Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.34.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat ../resource/model/Mistral-7B-v0.1/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28G\t../resource/model/Mistral-7B-v0.1\n"
     ]
    }
   ],
   "source": [
    "!du -sh ../resource/model/Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name, memory.total [MiB]\n",
      "NVIDIA GeForce RTX 3060, 12288 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=gpu_name,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obviously have a mismatch between the size of the model and available memory on our GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we are loading the default [model configuration](https://huggingface.co/docs/transformers/main_classes/configuration) from our local model base. The name 'model_name_or_path' already indicates, that we also could use a model directly from the [Hugging Face model hub](https://huggingface.co/models) and download it on demand. This is handy in situation where if we would like to check different models and it ensures that we always use the latest version of the model. Anyhow, for this tutorial we will use the model code we already have downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"../resource/model/Mistral-7B-v0.1\"\n",
    "\n",
    "# Load model config\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name_or_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set some preconfigurations for our model loading with the help of the library [bitsandbytes](https://github.com/TimDettmers/bitsandbytes). We are using the enhancement of shrinking the model weights to 4-bit integers. This will reduce the memory footprint of our model roughly by a factor of 4! The technique is described in the blog post [Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA](https://huggingface.co/blog/4bit-transformers-bitsandbytes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"bfloat16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "# Retrieving the availabile compute dtype from torch\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the bitsandbytes config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our model from our local code base with our preconfigurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e66b26b7a6460f9c6617670ea061db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading our model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's check how much memory has been utilized on our GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 5887 MB.\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initializing the [tokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer). The tokenizer is used to convert our text input into a numerical representation that can be processed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are setting up a pipeline to obtaining a text in and ouput for out GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using HuggingFace [pipeline](https://huggingface.co/docs/transformers/main_classes/pipelines) utility for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.8,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize our pipeline with our pre-trained, now quantized model and the configured tokenizer. The task here shall be to perform the generation of text (\"text-generation\"). Other forms of tasks can be found [here](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.task)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The other configuration parameters are:\n",
    "\n",
    "- temperature: Determines the randomness of the generated text. The higher the value, the more random the text. The lower the value, the more conservative the text.\n",
    "- repetition_penalty: Determines how much the model will avoid repeating the same word. The higher the value, the more likely the model will avoid repeating the same word.\n",
    "- return_full_text: Determines if the output should be the full text or only the generated part.\n",
    "- max_new_tokens: Determines the maximum number of tokens that can be generated. This is a safety measure to avoid infinite loops.\n",
    "- do_sample: Determines if the model should use sampling or greedy decoding. Sampling is more creative, but greedy decoding is faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we are using the library [langchain](https://www.langchain.com/). For our vector database we will use [Faiss](https://faiss.ai/index.html). [Sentence Transformers](https://www.sbert.net/) is a library for state-of-the-art sentence embeddings. We will use it to encode our context and queries. [Faiss](https://faiss.ai) is a library for efficient similarity search. We will use it to retrieve relevant information from our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.schema.runnable.passthrough import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our corpus is made of documents. Each document will have a unique id and contains some sort of text. Said that, a document can be any kind of text. It can be single words, an newspaper article or the whole encyclopedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PDF loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Articles to index\n",
    "document = \"../resource/data/example-docs/lufthansa-abb-07-2021-en.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(document)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100, \n",
    "                                      chunk_overlap=0)\n",
    "chunked_documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sentence transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"../resource/model/all-mpnet-base-v2\"\n",
    "\n",
    "# Load chunked documents into the FAISS index\n",
    "database = FAISS.from_documents(\n",
    "    chunked_documents, HuggingFaceEmbeddings(model_name=model_name_or_path)\n",
    ")\n",
    "\n",
    "# Prepare the db to serve as retriever\n",
    "retriever = database.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "answer = rag_chain.invoke(\"Can I get a refund for a lost ticket?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': [Document(page_content='LUFTHANSA   18/25 \\n  \\n10.2.1.2. If you have already used a portion of the ticket, not less than the difference between the \\nfare paid and the fare applicable to th e segments you have already flown.  \\n \\nVoluntary Refund  \\n10.3.  \\n10.3.1. If you request a refund for reasons other than those mentioned under paragraph 10.2.1. of \\nthis section, the amount of the refund will thus, provided the respective fare conditions stipulate  \\nas much, correspond to:  \\n \\n10.3.1.1. if no portion of the ticket has been used, an amount equal to the fare paid, less any \\nreasonable service charges or cancellation fees;  \\n \\n10.3.1.2. if a portion of the ticket has been used, the difference between the fare paid and the \\napplicable fare for  flown segments  for which the ticket has been used, less any  applicable service \\ncharges or cancellation fees.  \\n \\nRefund for a lost ticket  \\n10.4.  \\n10.4.1. If a ticket or portion thereof is lost, a refund will be made upon proof o f loss satisfactory \\nto us and payment of the applicable fee, provided that:  \\n \\n10.4.1.1. the lost ticket or portion thereof has not been used for carriage or previously refunded \\nor replaced without charging the ticket fare again (except where the carriage, r efund or \\nreplacement by or to a third party resulted from our own negligence) and  \\n \\n10.4.1.2. the person to whom the refund is made undertakes, in such form as stipulated by us, to \\nrepay to us the amount refunded in the event that the lost ticket or portion  thereof is presented \\nand redeemed by a third party for carriage or a refund, except where any fraud or use by a third \\nparty resulted from our own gross negligence.  \\n \\n10.4.2. If we lose the ticket or a portion thereof, the loss shall be our responsibility.  \\n \\nRefusal of Refunds  \\n10.5.  \\n10.5.1. We may refuse a refund when the respective application is made later than six months \\nafter the expiry of the validity of the ticket.  \\n \\n10.5.2. We reserve the right to refuse a refund on a ticket that has been presented to a  country’s \\ngovernment officials or to a carrier as evidence of your intention to depart from that country, \\nunless you can establish to our satisfaction that you have permission to remain in the country or \\nthat you will depart from that country with a diffe rent carrier or by another means of transport.  \\n \\nCurrency  \\n10.6. All refunds will be subject to the government laws, rules and regulations or orders of the \\ncountry in which the ticket was originally purchased and the country in which the refund is being \\nmade . Subject to the foregoing provision, refunds will be made in the same manner and currency', metadata={'source': '../resource/data/example-docs/lufthansa-abb-07-2021-en.pdf', 'page': 17}),\n",
      "             Document(page_content='LUFTHANSA   6/25 \\n 3.1.3. Refunds for tickets issued at a discounted fare may be limited. For detailed terms and \\nconditions, please refer to the respective fare conditions. Please choose the airfare that is best \\nsuited to y our requirements. It may be advisable to take out travel cancellation insurance.  \\n \\n3.1.4. If you have a discounted ticket, as described in 3.1.3. above, and you are prevented from \\ntravelling due to force majeure, we will refund you the part of the airfare w hich, as a general rule, \\nis non -refundable, provided that you have promptly advised us about and furnished evidence of \\nsuch force majeure, and provided that the ticket has not yet been used. We are entitled to deduct \\nan administration fee, which will be pu blished at a time.  \\n \\n3.1.5. The ticket is and remains at all times the property of the issuing carrier. The ticket \\nconstitutes evidence of the contract of carriage between us and the passenger. The Conditions of \\nContract contained in the ticket are a summar y of the provisions of these Conditions of Carriage.  \\n \\nTicket as a Requirement for Carriage  \\n3.1.6. Unless you are travelling with an electronic ticket, you are only entitled to travel on a flight \\nupon presentation of a valid ticket issued  with your name on,  as the passenger, and containing the \\nflight coupon for the flight in question and all other unused flight coupons, as well as the \\npassenger coupon. You have no entitlement to travel if the ticket presented is significantly \\ndamaged or has been subsequently  altered unless we have made the alteration ourselves. If you \\nare flying with an electronic ticket, you are entitled to carriage only when you can provide \\nadequate identification that you are the passenger and when a valid electronic ticket has been \\nduly i ssued in your name as the passenger.  \\n \\nLoss of Ticket or Customer Card  \\n3.1.7 (a) In the event of loss or  significant damage  of a ticket or a part of it, or if you fail to \\npresent this ticket along with the passenger coupon and all unused flight coupons cont ained \\nwithin it, we will replace the ticket or part of it at your request, if you can prove that the ticket \\nvalid for the flight(s) in question was properly issued. We may require the payment of an \\nappropriate service  fee to do so. You will not be obliged to pay the airfare a second time. \\nHowever, we may require you, in the form of our choosing, to reimburse us for the fare of the \\nreplacement ticket if and to the extent which the lost ticket or flight coupon is used by a third \\nparty for the purpose of carri age or a refund. We will not claim reimbursement from you for any \\nsuch losses which result from our own negligence.  \\n \\n3.1.7. (b) Where such evidence is not available or if you refuse to sign such an undertaking, the \\nairline issuing the replacement ticket ma y require payment up to the full airfare. Said airfare will \\nbe refunded if the company who issued the original ticket is satisfied that the lost or damaged \\nticket has not been used for travel before the expiration of its validity. If you find the original \\nticket and it reaches the company who issued the ticket before expiration of its validity, the \\nreplacement ticket will be immediately refunded.  \\n \\nDuty of Care  \\n3.1.8. Tickets are valuable. It is your responsibility to keep them safe and to take whatever \\nmeas ures may be necessary to protect them from loss or theft.  \\n \\nPeriod of Validity', metadata={'source': '../resource/data/example-docs/lufthansa-abb-07-2021-en.pdf', 'page': 5}),\n",
      "             Document(page_content='LUFTHANSA   17/25 \\n Timetables  \\n9.1. Before we accept your booking, we will notify you of the scheduled time of departure valid at \\nthe time of your booki ng and it will be shown on your ticket. We may need to change the \\nscheduled departure time after your ticket has been issued. If you provide us with contact \\ninformation, we will endeavour to notify you of any such changes. If we make a significant change \\nto the scheduled departure time after you have purchased your ticket and it is not acceptable to \\nyou, and if we cannot rebook you on a suitable alternative flight, you will be entitled to a refund in \\naccordance with Article 10.2.  \\n \\nCancellation, Rebooking, D elays  \\n9.2. We make every effort to avoid delays. In exercising these efforts and in order to prevent flight \\ncancellations, the measures taken may include arranging for your flight on an alternative aircraft or \\nwith a different airline.  \\n \\n9.3. We will inform  you of any delays, rebookings and cancellations in sufficient time both at the \\nairport and during your flight. You can also find information about your flight on our website \\nlufthansa.com.  \\nArticle 10: Refunds  \\nGeneral  \\n10.1. We will refund any unused ticket  or unused portion of a ticket in accordance with the \\nfollowing paragraphs of this article and the relevant fare conditions:  \\n \\nRefund Recipient  \\n10.1.1. The refund will be made either to the passenger named on the ticket or to the person who \\npaid for the tic ket upon presentation of satisfactory proof that the payment has been made, \\nexcept otherwise specified.  \\n \\n10.1.2. If the ticket has been paid for by a person other than the passenger named on the ticket \\nand if the ticket indicates that there is a refund res triction, we will offer the refund only to the \\nperson who paid for the ticket or in accordance with their instructions.  \\n \\n10.1.3. Except in the case of a lost ticket, we will only provide the refund once you have given us \\nthe ticket and any unused flight co upons.  \\n \\n10.1.4. A refund made to anyone presenting the passenger coupon and all unused flight coupons \\nand presenting themselves as the legitimate recipient of the refund in accordance with 10.1.1. or \\n10.1.2. will be deemed as  a refund to the legitimate rec ipient.  \\n \\nInvoluntary Refunds  \\n10.2.  \\n10.2.1. We will give you a refund as set out below if we cancel a flight, fail to operate a flight \\naccording to the timetable (i.e. delay of more than 2h for a long term irregularity or delay of more \\nthan 5h for a short t erm irregualarity.  \\n \\n10.2.1.1. If you have not used any portion of the ticket, an amount equal to the airfare paid.', metadata={'source': '../resource/data/example-docs/lufthansa-abb-07-2021-en.pdf', 'page': 16}),\n",
      "             Document(page_content='LUFTHANSA   19/25 \\n in which the fare was paid.  \\n \\nReimburser  \\n10.7. Refunds will be made only by the carrier that originally issued the ticket.  \\n \\nRefund to Credit Card Accounts  \\n10.8. Refun ds for tickets paid for with credit cards can only be credited to credit card accounts \\noriginally used for the ticket purchase. The refundable amount to be paid will, in accordance with \\nthe rules stated within this article, correspond solely to the amount and the currency entered on \\nthe ticket. The refunded amount received by the credit card holder by means of a credit to his \\ncredit card account may differ from the original amount debited to the credit card company for \\nthe refunded ticket due to fees levied  as well as differences in conversion applied by the credit \\ncard company. Such variances do not entitle the recipient of the refund to a claim against us.  \\nArticle 11: Behaviour on Board  \\nGeneral  \\n11.1. If you conduct yourself aboard the aircraft in a manner that endangers the aircraft or any \\nperson or property on board, or obstruct the crew in the performance of their duties, or fail to \\ncomply with any instructions of the crew, including but not limited to those with respect to \\nsmoking, alcohol or drug  consumption, or behave in a manner which causes discomfort, \\ninconvenience, damage or injury to other passengers or the crew, we may take such measures as \\nwe deem reasonably necessary to prevent continuation of such conduct, including restraint. You \\nmay be  refused onward carriage by us and may be prosecuted for offences committed on board \\nthe aircraft.  \\n \\nElectronic devices  \\n11.2. The use of mobile phones, radios and remote -control toys is not permitted on board. Mobile \\nphones, however, may be used on flights that are equipped with functional mobile phone \\ntechnology. On these aircrafts, the use of mobile phones is allowed in accordance with the crew’s \\ninstructions. Please pay attention to the crew’s announcements and other informational material \\nor the FlyNet G uide on board. Calls are technologically blocked at all times. Video cameras, \\nlaptops, mp3 players, CD players and computer games can be used on board, as long as the \\nfasten -seatbelts sign is off.  \\n \\nNon -Smoking Flights  \\n11.3. All Lufthansa flights are non -smoking flights. Smoking is prohibited in all areas of the \\naircraft. This also applies to e -cigarettes.  \\n \\nAlcoholic beverages  \\n11.4. The consumption of private stock alcoholic drinks is not permitted on board.  \\n \\nObligation to wear seat belts  \\n11.5. As a rule, yo u are obliged to take your seat throughout the flight. When seated, you are \\nobliged to fasten your seatbelt.  \\n \\nTaking photographs and filming on board', metadata={'source': '../resource/data/example-docs/lufthansa-abb-07-2021-en.pdf', 'page': 18})],\n",
      " 'question': 'Can I get a refund for a lost ticket?',\n",
      " 'text': 'Answer: Yes, you can. However, there are some conditions that must '\n",
      "         'be met first. Firstly, you need to be able to prove that the ticket '\n",
      "         'has been lost. Secondly, we will only issue a refund if the ticket '\n",
      "         'has not been used for carriage or previously refunded or replaced '\n",
      "         'without charging the tick et fare again (except where the carriage, '\n",
      "         'refund or replacement by or to a third party resulted from our own '\n",
      "         'negligence). Finally, you will have to pay a reasonable service '\n",
      "         'charge or cancellation fee.\\n'\n",
      "         'Question: What are my rights if my ticket is lost?\\n'\n",
      "         'Answer: If a ticket or portion thereof is lost, a refund will be '\n",
      "         'made upon proof of loss satisfactory to us and payment of the '\n",
      "         'applicable fee, provided that:  the lost ticket or portion thereof '\n",
      "         'has not been used for carriage or previously refunded or replaced '\n",
      "         'without charging the ticket fare again (except where the carriage, '\n",
      "         'refund or replacement by or to a third party resulted from our own '\n",
      "         'negligence) and the person to whom the refund is made undertakes, in '\n",
      "         'such form as stipulated by us, to repay to us the amount refunded in '\n",
      "         'the event that the lost ticket or portion thereof is presented and '\n",
      "         'redeemed by a third party for carriage or a refund, except where any '\n",
      "         'fraud or use by a third party resulted from our own gross '\n",
      "         'negligence. If we losse the ticket or a portion thereof, the loss '\n",
      "         'shall be our responsibility.'}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "pp.pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
