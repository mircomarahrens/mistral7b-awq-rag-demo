{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mircomarahrens/.cache/pypoetry/virtualenvs/mistral7b-awq-rag-demo-wl7TFlgK-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Replacing layers...: 100%|██████████| 32/32 [00:02<00:00, 11.64it/s]\n",
      "Fusing layers...: 100%|██████████| 32/32 [00:05<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "Output:  <s> Tell me about AI\n",
      "\n",
      "# What is AI?\n",
      "\n",
      "Artificial intelligence is the process of building smart machines that can perform tasks like a human. The term is applied when a machine mimics cognitive functions that humans associate with other human minds, such as learning and problem-solving.\n",
      "\n",
      "## AI explained\n",
      "\n",
      "Artificial intelligence (AI) is the process of building smart machines that can perform tasks like a human. The term is applied when a machine mimics cognitive functions that humans associate with other human minds, such as learning and problem-solving. AI has been the subject of science fiction for many decades. However, artificial intelligence is now being used in many fields, including medicine, finance, law, and business. The term was first coined by John McCarthy in 1956.\n",
      "\n",
      "## AI vs. machine learning\n",
      "\n",
      "Artificial intelligence is the broad term for the concept of machines performing tasks that would typically require human intelligence. Machine learning is a subset of artificial intelligence, which focuses on the development of algorithms that can learn and improve from experience.\n",
      "\n",
      "## Types of AI\n",
      "\n",
      "There are three main types of AI:\n",
      "\n",
      "### Artificial Narrow Intelligence (ANI)\n",
      "\n",
      "ANI is a type of artificial intelligence that is designed to perform a specific task, such as playing chess or driving a car. ANI is the most common type of AI in use today.\n",
      "\n",
      "### Artificial General Intelligence (AGI)\n",
      "\n",
      "AGI is a type of artificial intelligence that is designed to perform any intellectual task that a human can. AGI is not yet a reality, but it is the ultimate goal of many AI researchers.\n",
      "\n",
      "### Artificial Super Intelligence (ASI)\n",
      "\n",
      "ASI is a type of artificial intelligence that is more intelligent than any human. ASI is not yet a reality, but it is the ultimate goal of some AI researchers.\n",
      "\n",
      "## The history of AI\n",
      "\n",
      "Artificial intelligence has been the subject of science fiction for many decades. However, artificial intelligence is now being used in many fields, including medicine, finance, law, and business. The term was first coined by John McCarthy in 1956.\n",
      "\n",
      "## The future of AI\n",
      "\n",
      "The future of AI is exciting and full of potential. AI is already being used in many fields, including medicine, finance, law, and business. The ultimate goal of many AI researchers is to create artificial super intelligence (ASI), which is more intelligent than any\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Inference should be possible with transformers pipeline as well in future\\n# But currently this is not yet supported by AutoAWQ (correct as of September 25th 2023)\\nfrom transformers import pipeline\\n\\nprint(\"*** Pipeline:\")\\npipe = pipeline(\\n    \"text-generation\",\\n    model=model,\\n    tokenizer=tokenizer,\\n    max_new_tokens=512,\\n    do_sample=True,\\n    temperature=0.7,\\n    top_p=0.95,\\n    top_k=40,\\n    repetition_penalty=1.1\\n)\\n\\nprint(pipe(prompt_template)[0][\\'generated_text\\'])\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_or_path = \"../model/Mistral-7B-v0.1-AWQ\"\n",
    "\n",
    "# Load model\n",
    "model = AutoAWQForCausalLM.from_quantized(model_name_or_path, fuse_layers=True,\n",
    "                                          trust_remote_code=False, safetensors=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=False)\n",
    "\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''{prompt}\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "tokens = tokenizer(\n",
    "    prompt_template,\n",
    "    return_tensors='pt'\n",
    ").input_ids.cuda()\n",
    "\n",
    "# Generate output\n",
    "generation_output = model.generate(\n",
    "    tokens,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "print(\"Output: \", tokenizer.decode(generation_output[0]))\n",
    "\n",
    "\"\"\"\n",
    "# Inference should be possible with transformers pipeline as well in future\n",
    "# But currently this is not yet supported by AutoAWQ (correct as of September 25th 2023)\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "print(pipe(prompt_template)[0]['generated_text'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
