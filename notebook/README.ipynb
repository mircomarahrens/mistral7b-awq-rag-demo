{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-augmented generation with open-source large language models\n",
    "\n",
    "Info: This README is created with\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert --execute --to markdown notebook/README.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "The tested environment is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux richardfeynman 5.15.133.1-microsoft-standard-WSL2 #1 SMP Thu Oct 5 21:02:42 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n"
     ]
    }
   ],
   "source": [
    "!uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRIB_ID=Ubuntu\n",
      "DISTRIB_RELEASE=22.04\n",
      "DISTRIB_CODENAME=jammy\n",
      "DISTRIB_DESCRIPTION=\"Ubuntu 22.04.3 LTS\"\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/lsb-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39;1mPoetry\u001b[39;22m (version \u001b[36m1.5.1\u001b[39m)\n"
     ]
    }
   ],
   "source": [
    "!poetry --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/cuda/bin/nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name, memory.total [MiB]\n",
      "NVIDIA GeForce RTX 3060, 12288 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=gpu_name,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Using [poetry](https://python-poetry.org/)\n",
    "\n",
    "```bash\n",
    "poetry install\n",
    "```\n",
    "\n",
    "or using the provided `requirements.txt` with [pip](https://pip.pypa.io/en/stable/)\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation\n",
    "\n",
    "To enter a presentation, included in this repo, run\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert notebook/00_presentation.ipynb --to slides --post serve\n",
    "```\n",
    "\n",
    "This will open a browser window with the notebook rendered as slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- <https://python.langchain.com/docs/expression_language/cookbook/retrieval>\n",
    "- original model: <https://huggingface.co/mistralai/Mistral-7B-v0.1>\n",
    "- quantized model: <https://huggingface.co/TheBloke/Mistral-7B-v0.1-AWQ>\n",
    "- vllm: <https://docs.vllm.ai/>\n",
    "- autoawq:\n",
    "  - <https://docs.vllm.ai/en/latest/quantization/auto_awq.html>\n",
    "  - <https://github.com/casper-hansen/AutoAWQ>\n",
    "- <https://huggingface.co/TheBloke/SciPhi-Self-RAG-Mistral-7B-32k-AWQ>\n",
    "- <https://github.com/oobabooga/text-generation-webui>\n",
    "- <https://medium.com/@thakermadhav/build-your-own-rag-with-mistral-7b-and-langchain-97d0c92fa146>\n",
    "- <https://redis.io/docs/get-started/vector-database/>\n",
    "- <https://github.com/facebookresearch/faiss/wiki>\n",
    "- <https://github.com/TimDettmers/bitsandbytes>\n",
    "- <https://www.youtube.com/watch?v=IxrlHAJtqKE>\n",
    "- <https://research.ibm.com/blog/retrieval-augmented-generation-RAG>\n",
    "- NLP Course: <https://huggingface.co/learn/nlp-course/chapter1/1>\n",
    "- Quantization: <https://huggingface.co/docs/transformers/main_classes/quantization>\n",
    "- Tokenizer: <https://huggingface.co/docs/transformers/main_classes/tokenizer>\n",
    "- <https://python.langchain.com/docs/integrations/vectorstores/faiss>\n",
    "- <https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf>\n",
    "- <https://openai.com/blog/introducing-text-and-code-embeddings>\n",
    "\n",
    "## Papers\n",
    "\n",
    "- RAG: <https://arxiv.org/abs/2005.11401v4>\n",
    "- MistralAI paper: <https://arxiv.org/pdf/2310.06825.pdf>\n",
    "- OpenAI Text embeddings paper: <https://arxiv.org/abs/2201.10005>\n",
    "- Similarity search: <https://arxiv.org/abs/1702.08734>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-demo-ANNCJvwW-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
