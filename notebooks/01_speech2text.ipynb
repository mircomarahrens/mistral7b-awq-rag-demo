{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "\n",
    "inputs = tokenizer('''def print_prime(n):\n",
    "   \"\"\"\n",
    "   Print all primes between 1 and n\n",
    "   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type phi-msft to instantiate a model of type speech_to_text. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00228f7b37141d49cb79f8d3e3b05c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Speech2TextForConditionalGeneration were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['encoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.0.fc2.bias', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.2.fc1.bias', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.fc1.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn.k_proj.weight', 'encoder.layers.0.fc2.weight', 'decoder.layers.2.final_layer_norm.weight', 'encoder.layers.6.self_attn.v_proj.weight', 'encoder.layers.0.final_layer_norm.weight', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.4.fc2.weight', 'encoder.embed_positions.weights', 'decoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.6.self_attn.out_proj.bias', 'encoder.layers.8.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.6.fc1.bias', 'encoder.layers.9.fc1.bias', 'encoder.layers.11.fc1.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.8.self_attn.q_proj.bias', 'encoder.layers.1.fc1.bias', 'encoder.layers.11.self_attn_layer_norm.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.8.self_attn_layer_norm.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'encoder.layers.9.fc2.bias', 'decoder.layer_norm.bias', 'encoder.layers.6.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.2.fc2.weight', 'encoder.layers.10.fc1.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'encoder.layers.8.self_attn.out_proj.bias', 'decoder.layers.5.fc2.bias', 'encoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.3.fc1.bias', 'decoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.7.self_attn.q_proj.weight', 'encoder.layers.3.final_layer_norm.weight', 'decoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.10.fc1.bias', 'encoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.weight', 'encoder.layers.11.fc1.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.9.self_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'encoder.layers.10.fc2.bias', 'decoder.layers.5.encoder_attn.q_proj.bias', 'encoder.layers.3.fc2.bias', 'encoder.conv.conv_layers.1.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'encoder.layer_norm.bias', 'encoder.layers.6.self_attn.v_proj.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.7.fc1.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.fc2.weight', 'encoder.layers.6.fc1.weight', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.final_layer_norm.bias', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.7.self_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.1.fc2.weight', 'decoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.6.self_attn.k_proj.bias', 'encoder.layers.9.self_attn.out_proj.bias', 'encoder.layers.7.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.8.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.conv.conv_layers.0.bias', 'encoder.layers.9.self_attn_layer_norm.bias', 'decoder.layers.0.fc2.weight', 'encoder.layers.10.self_attn_layer_norm.weight', 'decoder.layers.4.fc2.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'encoder.layers.9.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'encoder.layers.7.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.7.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.8.fc2.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.8.final_layer_norm.bias', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.2.fc2.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.10.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.8.self_attn.out_proj.weight', 'encoder.layers.10.self_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.4.fc1.bias', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.11.self_attn_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'encoder.layers.8.self_attn.k_proj.weight', 'encoder.layers.9.fc2.weight', 'decoder.layers.5.fc1.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.11.fc2.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.0.fc1.bias', 'encoder.layers.0.fc1.bias', 'encoder.layers.9.final_layer_norm.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.4.fc2.bias', 'decoder.layers.1.fc2.bias', 'encoder.layers.6.self_attn_layer_norm.weight', 'encoder.layers.7.self_attn.k_proj.bias', 'encoder.layers.8.fc2.weight', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.weight', 'encoder.layers.11.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.10.self_attn_layer_norm.bias', 'encoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.0.final_layer_norm.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.1.fc1.bias', 'decoder.layers.5.final_layer_norm.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'encoder.layers.6.final_layer_norm.bias', 'decoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layer_norm.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.conv.conv_layers.0.weight', 'encoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.11.self_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'encoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.7.final_layer_norm.bias', 'decoder.layers.0.final_layer_norm.bias', 'encoder.layers.7.self_attn.v_proj.weight', 'encoder.layers.8.fc1.bias', 'encoder.layers.11.fc2.bias', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.9.fc1.weight', 'encoder.layers.11.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.2.fc1.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'lm_head.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.9.self_attn.v_proj.bias', 'encoder.layers.9.self_attn.q_proj.weight', 'encoder.layers.5.fc2.weight', 'decoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.11.final_layer_norm.bias', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.8.self_attn_layer_norm.weight', 'encoder.layers.7.self_attn.out_proj.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.self_attn.k_proj.bias', 'encoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.bias', 'encoder.layers.7.self_attn.k_proj.weight', 'encoder.layers.1.final_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.3.final_layer_norm.bias', 'encoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.8.fc1.weight', 'decoder.layers.3.fc1.weight', 'encoder.layers.10.self_attn.out_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.4.fc1.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.6.fc2.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.5.final_layer_norm.bias', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.6.self_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'encoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.2.fc1.bias', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.4.final_layer_norm.weight', 'encoder.conv.conv_layers.1.weight', 'encoder.layers.10.final_layer_norm.bias', 'decoder.embed_positions.weights', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.11.self_attn.k_proj.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.final_layer_norm.weight', 'encoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.7.fc1.weight', 'encoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.bias', 'encoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.9.self_attn.v_proj.weight', 'encoder.layers.10.fc2.weight', 'encoder.layers.7.fc2.weight', 'encoder.layers.2.final_layer_norm.bias', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.embed_tokens.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.11.self_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'encoder.layers.7.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'encoder.layers.10.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.6.self_attn_layer_norm.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.8.self_attn.v_proj.bias', 'encoder.layers.9.self_attn.q_proj.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.4.fc1.weight', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.fc1.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.8.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layer_norm.weight', 'encoder.layers.6.fc2.bias', 'decoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.11.self_attn.out_proj.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'encoder.layers.4.final_layer_norm.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.k_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"microsoft/phi-2\")\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "# ds = load_dataset(\"audiofolder\", data_dir=\"../resource/data/audio/\")\n",
    "\n",
    "# inputs = processor(ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\")\n",
    "\n",
    "# generated_ids = model.generate(inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n",
    "\n",
    "# transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "# transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "microsoft/phi-2 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/microsoft/phi-2/main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:270\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/microsoft/phi-2/resolve/main/preprocessor_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/transformers/utils/hub.py:389\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1247\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1247\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1624\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1624\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1633\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:402\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 402\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:426\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    425\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 426\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:280\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    279\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EntryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-658414a1-62b7620639b64be17ff6e158;e7240f83-aaa3-4a1e-8490-533759f366bd)\n\nEntry Not Found for url: https://huggingface.co/microsoft/phi-2/resolve/main/preprocessor_config.json.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Speech2TextProcessor\n\u001b[0;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mSpeech2TextProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/phi-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/transformers/processing_utils.py:228\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m--> 228\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/transformers/processing_utils.py:272\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 272\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:373\u001b[0m, in \u001b[0;36mFeatureExtractionMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m--> 373\u001b[0m feature_extractor_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_extractor_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dict(feature_extractor_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/transformers/feature_extraction_utils.py:498\u001b[0m, in \u001b[0;36mFeatureExtractionMixin.get_feature_extractor_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m feature_extractor_file \u001b[38;5;241m=\u001b[39m FEATURE_EXTRACTOR_NAME\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m     resolved_feature_extractor_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_extractor_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/transformers/utils/hub.py:440\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m         revision \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# First we try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, revision\u001b[38;5;241m=\u001b[39mrevision)\n",
      "\u001b[0;31mOSError\u001b[0m: microsoft/phi-2 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/microsoft/phi-2/main' for available files."
     ]
    }
   ],
   "source": [
    "from transformers import Speech2TextProcessor\n",
    "\n",
    "tokenizer = Speech2TextProcessor.from_pretrained(\"microsoft/phi-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "You are using a model of type phi-msft to instantiate a model of type phi. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d96900052f04b01aaf81249ed78bb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['transformer.h.15.mixer.out_proj.bias', 'transformer.h.10.ln.weight', 'transformer.h.9.mixer.out_proj.weight', 'transformer.h.24.ln.bias', 'transformer.h.28.mlp.fc1.weight', 'transformer.h.25.mixer.Wqkv.weight', 'transformer.h.1.mixer.out_proj.weight', 'transformer.h.7.mixer.out_proj.weight', 'transformer.h.10.mlp.fc1.bias', 'transformer.h.16.mixer.Wqkv.bias', 'transformer.h.20.mixer.Wqkv.weight', 'transformer.h.25.mlp.fc2.weight', 'transformer.h.21.mixer.Wqkv.weight', 'transformer.h.13.mixer.Wqkv.bias', 'transformer.h.27.mixer.Wqkv.weight', 'transformer.h.26.ln.bias', 'transformer.h.26.mlp.fc1.weight', 'transformer.h.10.mixer.Wqkv.weight', 'transformer.h.29.mlp.fc2.weight', 'transformer.h.15.mlp.fc1.weight', 'transformer.h.24.ln.weight', 'transformer.h.5.mixer.out_proj.bias', 'transformer.h.30.ln.bias', 'transformer.h.8.mlp.fc1.bias', 'transformer.h.11.ln.bias', 'transformer.h.30.mlp.fc1.weight', 'transformer.h.26.mixer.Wqkv.bias', 'transformer.h.18.mlp.fc2.weight', 'transformer.h.0.mixer.out_proj.weight', 'transformer.h.22.mixer.out_proj.weight', 'transformer.h.2.mlp.fc1.bias', 'transformer.h.31.mlp.fc2.bias', 'transformer.h.27.ln.weight', 'transformer.h.19.mixer.out_proj.bias', 'transformer.h.1.mlp.fc2.bias', 'transformer.h.17.mlp.fc1.weight', 'transformer.h.2.ln.bias', 'transformer.h.1.mlp.fc1.bias', 'transformer.h.25.mlp.fc1.weight', 'transformer.h.12.mixer.out_proj.weight', 'transformer.h.15.ln.bias', 'transformer.h.29.mixer.Wqkv.bias', 'transformer.h.14.mlp.fc1.bias', 'transformer.h.21.mlp.fc2.bias', 'transformer.h.9.mlp.fc2.bias', 'transformer.h.12.mixer.out_proj.bias', 'transformer.h.11.mixer.Wqkv.weight', 'transformer.h.20.mixer.out_proj.weight', 'transformer.h.15.mlp.fc2.bias', 'transformer.h.25.mlp.fc1.bias', 'transformer.h.17.ln.weight', 'transformer.h.6.mixer.out_proj.bias', 'transformer.h.31.ln.weight', 'transformer.h.16.mlp.fc2.weight', 'transformer.h.8.mixer.out_proj.bias', 'transformer.h.25.mixer.out_proj.weight', 'transformer.h.4.mixer.out_proj.bias', 'transformer.h.3.mlp.fc2.weight', 'transformer.h.0.ln.weight', 'transformer.h.27.mlp.fc1.bias', 'transformer.h.12.ln.bias', 'transformer.h.8.mlp.fc2.bias', 'transformer.h.20.mlp.fc1.bias', 'transformer.h.27.mlp.fc2.bias', 'transformer.h.9.mixer.Wqkv.bias', 'transformer.h.23.mlp.fc1.weight', 'transformer.h.17.mixer.out_proj.bias', 'transformer.h.19.ln.weight', 'transformer.h.29.ln.weight', 'transformer.h.10.mixer.Wqkv.bias', 'transformer.h.24.mixer.out_proj.bias', 'transformer.h.3.ln.weight', 'transformer.h.27.mixer.out_proj.weight', 'transformer.h.11.ln.weight', 'transformer.h.29.mlp.fc2.bias', 'transformer.h.6.mixer.Wqkv.bias', 'transformer.h.2.ln.weight', 'transformer.h.16.mlp.fc1.bias', 'transformer.h.31.mlp.fc1.weight', 'transformer.h.21.ln.bias', 'transformer.h.31.mlp.fc1.bias', 'transformer.h.9.ln.bias', 'transformer.h.4.ln.weight', 'transformer.h.13.ln.bias', 'transformer.h.15.mixer.Wqkv.weight', 'transformer.h.29.mixer.out_proj.weight', 'transformer.h.31.mixer.Wqkv.weight', 'transformer.h.28.mlp.fc1.bias', 'transformer.h.11.mixer.out_proj.bias', 'transformer.h.30.mlp.fc1.bias', 'transformer.h.20.mlp.fc1.weight', 'transformer.h.18.mixer.out_proj.bias', 'transformer.h.9.mlp.fc2.weight', 'transformer.h.22.ln.bias', 'transformer.h.19.mlp.fc1.weight', 'transformer.h.18.mlp.fc2.bias', 'transformer.h.25.ln.bias', 'transformer.h.10.mixer.out_proj.bias', 'transformer.h.22.mixer.out_proj.bias', 'transformer.h.12.mlp.fc1.weight', 'transformer.h.16.mlp.fc1.weight', 'transformer.h.28.mixer.out_proj.bias', 'transformer.h.14.mixer.Wqkv.bias', 'transformer.h.29.mlp.fc1.weight', 'transformer.h.9.mlp.fc1.bias', 'transformer.h.10.mlp.fc2.weight', 'transformer.h.0.mlp.fc1.bias', 'transformer.h.11.mixer.Wqkv.bias', 'transformer.h.19.mixer.out_proj.weight', 'transformer.h.15.ln.weight', 'transformer.h.1.mixer.out_proj.bias', 'lm_head.ln.bias', 'transformer.h.15.mlp.fc1.bias', 'transformer.h.2.mlp.fc1.weight', 'transformer.h.5.ln.weight', 'transformer.h.27.mlp.fc1.weight', 'transformer.h.12.mlp.fc2.bias', 'transformer.h.11.mlp.fc2.weight', 'transformer.h.28.mixer.Wqkv.weight', 'transformer.h.15.mixer.Wqkv.bias', 'transformer.h.20.mlp.fc2.weight', 'transformer.h.16.ln.weight', 'transformer.h.22.mixer.Wqkv.bias', 'transformer.h.10.mixer.out_proj.weight', 'transformer.h.18.mixer.Wqkv.bias', 'transformer.h.14.mixer.out_proj.bias', 'transformer.h.20.ln.bias', 'transformer.h.30.mixer.Wqkv.weight', 'transformer.h.7.mixer.Wqkv.bias', 'transformer.h.18.mlp.fc1.weight', 'transformer.h.9.ln.weight', 'transformer.h.23.ln.weight', 'transformer.h.5.mlp.fc1.weight', 'transformer.h.4.mixer.out_proj.weight', 'transformer.h.1.mixer.Wqkv.weight', 'transformer.h.21.mixer.Wqkv.bias', 'transformer.h.20.mixer.out_proj.bias', 'transformer.h.3.ln.bias', 'transformer.h.22.mlp.fc1.weight', 'transformer.h.18.mixer.out_proj.weight', 'transformer.h.26.mlp.fc2.bias', 'transformer.h.16.mlp.fc2.bias', 'transformer.h.30.mlp.fc2.bias', 'transformer.h.23.mixer.out_proj.bias', 'transformer.h.24.mixer.Wqkv.bias', 'transformer.h.27.mixer.out_proj.bias', 'transformer.h.10.ln.bias', 'transformer.h.6.mixer.Wqkv.weight', 'transformer.h.4.mlp.fc1.bias', 'transformer.h.22.mixer.Wqkv.weight', 'transformer.h.18.mlp.fc1.bias', 'transformer.h.26.mixer.Wqkv.weight', 'transformer.h.30.ln.weight', 'transformer.h.24.mlp.fc1.bias', 'transformer.h.8.ln.bias', 'transformer.h.13.mixer.Wqkv.weight', 'transformer.h.14.mixer.Wqkv.weight', 'transformer.h.19.mlp.fc2.weight', 'transformer.h.22.mlp.fc1.bias', 'transformer.h.17.mixer.Wqkv.bias', 'transformer.h.19.mlp.fc1.bias', 'transformer.h.17.ln.bias', 'transformer.h.8.mlp.fc2.weight', 'transformer.h.7.mixer.out_proj.bias', 'transformer.h.3.mixer.out_proj.bias', 'transformer.h.12.mlp.fc1.bias', 'transformer.h.2.mlp.fc2.weight', 'transformer.h.1.mlp.fc1.weight', 'transformer.h.19.mixer.Wqkv.bias', 'transformer.h.28.mlp.fc2.bias', 'transformer.h.2.mlp.fc2.bias', 'transformer.h.6.ln.bias', 'transformer.h.19.mlp.fc2.bias', 'transformer.h.18.mixer.Wqkv.weight', 'transformer.h.30.mixer.out_proj.bias', 'transformer.h.21.mlp.fc2.weight', 'transformer.h.6.mlp.fc1.weight', 'transformer.h.16.mixer.out_proj.bias', 'transformer.h.22.mlp.fc2.bias', 'transformer.h.2.mixer.out_proj.bias', 'transformer.h.3.mlp.fc1.bias', 'transformer.h.7.mixer.Wqkv.weight', 'transformer.h.13.ln.weight', 'transformer.h.14.mixer.out_proj.weight', 'transformer.h.28.mixer.Wqkv.bias', 'transformer.h.0.mixer.Wqkv.bias', 'transformer.h.5.mixer.Wqkv.weight', 'lm_head.linear.bias', 'transformer.h.24.mlp.fc2.bias', 'transformer.h.25.mixer.out_proj.bias', 'transformer.h.3.mixer.out_proj.weight', 'transformer.h.19.mixer.Wqkv.weight', 'transformer.h.23.ln.bias', 'transformer.h.26.mlp.fc1.bias', 'transformer.h.3.mixer.Wqkv.bias', 'transformer.h.23.mlp.fc2.weight', 'transformer.h.26.ln.weight', 'transformer.h.11.mlp.fc1.bias', 'transformer.h.7.mlp.fc2.bias', 'transformer.h.17.mlp.fc1.bias', 'transformer.h.4.mlp.fc1.weight', 'transformer.h.12.mixer.Wqkv.weight', 'transformer.h.23.mlp.fc1.bias', 'transformer.h.29.mixer.Wqkv.weight', 'transformer.h.19.ln.bias', 'transformer.h.27.ln.bias', 'transformer.h.31.ln.bias', 'transformer.h.21.ln.weight', 'transformer.h.23.mixer.out_proj.weight', 'transformer.h.24.mixer.out_proj.weight', 'transformer.h.20.mixer.Wqkv.bias', 'transformer.h.11.mlp.fc1.weight', 'transformer.h.8.ln.weight', 'transformer.h.1.ln.bias', 'transformer.h.28.ln.bias', 'transformer.h.5.ln.bias', 'transformer.h.25.mlp.fc2.bias', 'transformer.h.13.mlp.fc1.weight', 'transformer.h.0.ln.bias', 'transformer.h.28.ln.weight', 'transformer.h.8.mixer.Wqkv.weight', 'transformer.h.26.mixer.out_proj.weight', 'transformer.h.24.mlp.fc2.weight', 'transformer.h.29.mlp.fc1.bias', 'transformer.h.21.mixer.out_proj.weight', 'transformer.h.16.mixer.out_proj.weight', 'transformer.embd.wte.weight', 'transformer.h.5.mlp.fc2.bias', 'transformer.h.30.mlp.fc2.weight', 'transformer.h.14.ln.weight', 'transformer.h.9.mixer.Wqkv.weight', 'transformer.h.30.mixer.out_proj.weight', 'transformer.h.21.mlp.fc1.bias', 'transformer.h.23.mixer.Wqkv.bias', 'transformer.h.22.ln.weight', 'transformer.h.30.mixer.Wqkv.bias', 'transformer.h.21.mlp.fc1.weight', 'transformer.h.0.mixer.out_proj.bias', 'transformer.h.25.mixer.Wqkv.bias', 'transformer.h.12.mlp.fc2.weight', 'transformer.h.17.mlp.fc2.weight', 'transformer.h.1.ln.weight', 'transformer.h.6.mlp.fc2.bias', 'transformer.h.2.mixer.Wqkv.bias', 'transformer.h.7.mlp.fc1.weight', 'transformer.h.6.ln.weight', 'transformer.h.10.mlp.fc1.weight', 'transformer.h.31.mlp.fc2.weight', 'transformer.h.13.mlp.fc1.bias', 'transformer.h.5.mixer.out_proj.weight', 'transformer.h.22.mlp.fc2.weight', 'transformer.h.4.mlp.fc2.bias', 'transformer.h.8.mlp.fc1.weight', 'transformer.h.16.mixer.Wqkv.weight', 'transformer.h.10.mlp.fc2.bias', 'transformer.h.31.mixer.out_proj.weight', 'transformer.h.12.ln.weight', 'transformer.h.17.mlp.fc2.bias', 'transformer.h.14.mlp.fc2.bias', 'transformer.h.13.mlp.fc2.weight', 'transformer.h.4.mixer.Wqkv.bias', 'transformer.h.24.mlp.fc1.weight', 'transformer.h.15.mlp.fc2.weight', 'transformer.h.24.mixer.Wqkv.weight', 'transformer.h.17.mixer.Wqkv.weight', 'transformer.h.11.mlp.fc2.bias', 'transformer.h.1.mlp.fc2.weight', 'transformer.h.4.ln.bias', 'transformer.h.7.mlp.fc2.weight', 'transformer.h.6.mixer.out_proj.weight', 'transformer.h.5.mlp.fc2.weight', 'transformer.h.1.mixer.Wqkv.bias', 'transformer.h.21.mixer.out_proj.bias', 'transformer.h.6.mlp.fc1.bias', 'transformer.h.29.mixer.out_proj.bias', 'transformer.h.4.mlp.fc2.weight', 'transformer.h.17.mixer.out_proj.weight', 'transformer.h.16.ln.bias', 'transformer.h.13.mlp.fc2.bias', 'transformer.h.20.ln.weight', 'transformer.h.13.mixer.out_proj.weight', 'transformer.h.7.ln.bias', 'transformer.h.29.ln.bias', 'transformer.h.3.mlp.fc2.bias', 'transformer.h.0.mixer.Wqkv.weight', 'transformer.h.23.mixer.Wqkv.weight', 'transformer.h.6.mlp.fc2.weight', 'transformer.h.8.mixer.out_proj.weight', 'transformer.h.28.mixer.out_proj.weight', 'transformer.h.3.mixer.Wqkv.weight', 'transformer.h.5.mlp.fc1.bias', 'transformer.h.18.ln.weight', 'transformer.h.12.mixer.Wqkv.bias', 'transformer.h.18.ln.bias', 'transformer.h.2.mixer.Wqkv.weight', 'transformer.h.13.mixer.out_proj.bias', 'transformer.h.7.ln.weight', 'transformer.h.0.mlp.fc2.weight', 'transformer.h.4.mixer.Wqkv.weight', 'transformer.h.23.mlp.fc2.bias', 'transformer.h.9.mixer.out_proj.bias', 'transformer.h.14.mlp.fc2.weight', 'transformer.h.25.ln.weight', 'transformer.h.31.mixer.Wqkv.bias', 'transformer.h.2.mixer.out_proj.weight', 'transformer.h.28.mlp.fc2.weight', 'transformer.h.3.mlp.fc1.weight', 'transformer.h.8.mixer.Wqkv.bias', 'transformer.h.0.mlp.fc1.weight', 'transformer.h.14.ln.bias', 'transformer.h.27.mlp.fc2.weight', 'transformer.h.26.mixer.out_proj.bias', 'transformer.h.5.mixer.Wqkv.bias', 'transformer.h.14.mlp.fc1.weight', 'lm_head.linear.weight', 'transformer.h.27.mixer.Wqkv.bias', 'transformer.h.26.mlp.fc2.weight', 'transformer.h.9.mlp.fc1.weight', 'transformer.h.7.mlp.fc1.bias', 'transformer.h.15.mixer.out_proj.weight', 'lm_head.ln.weight', 'transformer.h.31.mixer.out_proj.bias', 'transformer.h.11.mixer.out_proj.weight', 'transformer.h.20.mlp.fc2.bias', 'transformer.h.0.mlp.fc2.bias']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['layers.4.self_attn.dense.bias', 'layers.3.input_layernorm.weight', 'layers.17.mlp.fc1.bias', 'layers.12.mlp.fc2.bias', 'layers.8.input_layernorm.weight', 'layers.19.self_attn.dense.weight', 'layers.11.input_layernorm.weight', 'layers.20.self_attn.dense.bias', 'layers.9.mlp.fc1.bias', 'layers.21.mlp.fc1.weight', 'layers.19.mlp.fc2.weight', 'layers.0.self_attn.query_key_value.bias', 'layers.12.self_attn.dense.weight', 'layers.21.mlp.fc2.weight', 'layers.1.mlp.fc2.bias', 'layers.12.mlp.fc1.bias', 'layers.10.mlp.fc2.weight', 'layers.13.mlp.fc2.weight', 'layers.2.self_attn.dense.weight', 'layers.18.self_attn.dense.weight', 'layers.18.mlp.fc1.weight', 'layers.13.mlp.fc1.weight', 'layers.13.self_attn.dense.weight', 'layers.16.mlp.fc1.weight', 'layers.7.input_layernorm.weight', 'layers.3.mlp.fc1.bias', 'layers.22.mlp.fc2.bias', 'layers.20.mlp.fc2.weight', 'layers.14.input_layernorm.bias', 'layers.16.self_attn.query_key_value.weight', 'layers.20.mlp.fc2.bias', 'layers.22.mlp.fc2.weight', 'layers.16.input_layernorm.bias', 'layers.7.self_attn.dense.weight', 'layers.9.mlp.fc2.bias', 'layers.10.input_layernorm.bias', 'layers.15.self_attn.dense.bias', 'layers.20.input_layernorm.weight', 'layers.22.self_attn.query_key_value.weight', 'layers.20.self_attn.query_key_value.bias', 'layers.7.mlp.fc1.bias', 'layers.3.self_attn.query_key_value.weight', 'layers.11.mlp.fc2.bias', 'layers.16.mlp.fc2.weight', 'layers.21.mlp.fc1.bias', 'layers.21.self_attn.dense.bias', 'layers.20.mlp.fc1.weight', 'layers.7.mlp.fc2.weight', 'layers.23.self_attn.query_key_value.weight', 'layers.7.self_attn.query_key_value.weight', 'layers.12.self_attn.query_key_value.bias', 'layers.16.mlp.fc2.bias', 'layers.12.self_attn.dense.bias', 'layers.8.input_layernorm.bias', 'layers.14.mlp.fc2.bias', 'layers.4.self_attn.dense.weight', 'layers.3.input_layernorm.bias', 'layers.9.self_attn.dense.weight', 'layers.8.self_attn.dense.bias', 'layers.23.input_layernorm.weight', 'layers.3.mlp.fc2.bias', 'layers.14.self_attn.dense.weight', 'layers.7.self_attn.query_key_value.bias', 'layers.5.input_layernorm.bias', 'layers.7.mlp.fc1.weight', 'layers.4.mlp.fc1.bias', 'layers.9.self_attn.query_key_value.bias', 'layers.22.self_attn.dense.bias', 'layers.6.self_attn.dense.bias', 'layers.11.self_attn.dense.bias', 'layers.23.self_attn.dense.bias', 'layers.13.input_layernorm.weight', 'layers.13.self_attn.query_key_value.weight', 'layers.22.input_layernorm.weight', 'layers.17.self_attn.dense.bias', 'layers.0.self_attn.dense.weight', 'layers.14.self_attn.dense.bias', 'layers.6.mlp.fc2.weight', 'layers.2.self_attn.dense.bias', 'layers.2.mlp.fc1.weight', 'layers.8.self_attn.query_key_value.weight', 'layers.18.self_attn.query_key_value.weight', 'embed_tokens.weight', 'layers.11.self_attn.dense.weight', 'layers.18.input_layernorm.bias', 'layers.18.mlp.fc1.bias', 'layers.18.mlp.fc2.bias', 'layers.6.mlp.fc2.bias', 'layers.17.mlp.fc2.bias', 'layers.18.self_attn.query_key_value.bias', 'layers.1.self_attn.dense.weight', 'layers.3.mlp.fc1.weight', 'layers.19.self_attn.query_key_value.weight', 'layers.19.input_layernorm.bias', 'layers.12.mlp.fc1.weight', 'layers.15.mlp.fc1.weight', 'layers.6.self_attn.query_key_value.weight', 'layers.0.mlp.fc1.bias', 'layers.20.self_attn.dense.weight', 'layers.4.mlp.fc2.weight', 'layers.15.mlp.fc1.bias', 'layers.14.mlp.fc1.bias', 'layers.7.mlp.fc2.bias', 'layers.9.self_attn.dense.bias', 'layers.22.self_attn.query_key_value.bias', 'layers.5.self_attn.query_key_value.weight', 'layers.0.input_layernorm.bias', 'layers.10.input_layernorm.weight', 'layers.14.mlp.fc2.weight', 'layers.6.input_layernorm.bias', 'layers.19.input_layernorm.weight', 'final_layernorm.weight', 'layers.14.self_attn.query_key_value.weight', 'layers.5.mlp.fc1.bias', 'layers.13.mlp.fc1.bias', 'layers.18.mlp.fc2.weight', 'layers.3.mlp.fc2.weight', 'layers.14.mlp.fc1.weight', 'layers.5.self_attn.dense.weight', 'layers.8.mlp.fc1.bias', 'layers.9.self_attn.query_key_value.weight', 'layers.17.input_layernorm.bias', 'layers.15.input_layernorm.bias', 'layers.4.self_attn.query_key_value.weight', 'layers.4.mlp.fc2.bias', 'layers.3.self_attn.query_key_value.bias', 'layers.9.mlp.fc2.weight', 'final_layernorm.bias', 'layers.17.mlp.fc1.weight', 'layers.21.input_layernorm.bias', 'layers.10.mlp.fc1.weight', 'layers.11.mlp.fc1.bias', 'layers.10.self_attn.query_key_value.weight', 'layers.5.input_layernorm.weight', 'layers.14.self_attn.query_key_value.bias', 'layers.23.mlp.fc2.bias', 'layers.9.input_layernorm.weight', 'layers.3.self_attn.dense.weight', 'layers.21.mlp.fc2.bias', 'layers.3.self_attn.dense.bias', 'lm_head.weight', 'layers.1.mlp.fc2.weight', 'layers.17.self_attn.query_key_value.weight', 'layers.23.mlp.fc1.bias', 'layers.8.self_attn.dense.weight', 'layers.2.input_layernorm.weight', 'layers.4.input_layernorm.weight', 'layers.1.mlp.fc1.weight', 'layers.1.input_layernorm.bias', 'layers.2.mlp.fc2.weight', 'layers.1.input_layernorm.weight', 'layers.6.input_layernorm.weight', 'layers.10.self_attn.dense.bias', 'layers.1.self_attn.query_key_value.weight', 'layers.4.self_attn.query_key_value.bias', 'layers.2.input_layernorm.bias', 'layers.18.self_attn.dense.bias', 'layers.15.input_layernorm.weight', 'layers.13.mlp.fc2.bias', 'layers.6.mlp.fc1.bias', 'layers.8.mlp.fc2.weight', 'layers.20.input_layernorm.bias', 'layers.14.input_layernorm.weight', 'layers.16.input_layernorm.weight', 'layers.19.self_attn.dense.bias', 'layers.5.self_attn.dense.bias', 'layers.19.mlp.fc1.bias', 'layers.1.mlp.fc1.bias', 'layers.11.input_layernorm.bias', 'layers.11.mlp.fc2.weight', 'layers.18.input_layernorm.weight', 'layers.11.self_attn.query_key_value.bias', 'layers.23.self_attn.dense.weight', 'layers.11.mlp.fc1.weight', 'layers.8.self_attn.query_key_value.bias', 'layers.21.self_attn.dense.weight', 'layers.13.input_layernorm.bias', 'layers.5.mlp.fc2.bias', 'layers.8.mlp.fc1.weight', 'layers.16.self_attn.dense.bias', 'layers.4.input_layernorm.bias', 'layers.2.self_attn.query_key_value.weight', 'layers.0.self_attn.query_key_value.weight', 'layers.19.self_attn.query_key_value.bias', 'layers.1.self_attn.dense.bias', 'layers.22.mlp.fc1.weight', 'layers.13.self_attn.dense.bias', 'layers.17.self_attn.dense.weight', 'layers.10.self_attn.query_key_value.bias', 'layers.5.self_attn.query_key_value.bias', 'layers.17.self_attn.query_key_value.bias', 'layers.6.self_attn.dense.weight', 'layers.20.mlp.fc1.bias', 'layers.23.mlp.fc2.weight', 'layers.15.mlp.fc2.weight', 'layers.17.mlp.fc2.weight', 'layers.23.input_layernorm.bias', 'layers.20.self_attn.query_key_value.weight', 'layers.9.mlp.fc1.weight', 'layers.21.self_attn.query_key_value.bias', 'layers.16.self_attn.dense.weight', 'layers.12.input_layernorm.weight', 'layers.10.mlp.fc1.bias', 'layers.21.input_layernorm.weight', 'layers.21.self_attn.query_key_value.weight', 'layers.22.input_layernorm.bias', 'layers.23.mlp.fc1.weight', 'layers.0.mlp.fc1.weight', 'layers.6.mlp.fc1.weight', 'layers.7.self_attn.dense.bias', 'layers.12.input_layernorm.bias', 'lm_head.bias', 'layers.17.input_layernorm.weight', 'layers.0.mlp.fc2.weight', 'layers.15.mlp.fc2.bias', 'layers.8.mlp.fc2.bias', 'layers.2.self_attn.query_key_value.bias', 'layers.2.mlp.fc1.bias', 'layers.7.input_layernorm.bias', 'layers.6.self_attn.query_key_value.bias', 'layers.12.self_attn.query_key_value.weight', 'layers.12.mlp.fc2.weight', 'layers.22.mlp.fc1.bias', 'layers.10.mlp.fc2.bias', 'layers.10.self_attn.dense.weight', 'layers.11.self_attn.query_key_value.weight', 'layers.15.self_attn.query_key_value.bias', 'layers.0.self_attn.dense.bias', 'layers.5.mlp.fc1.weight', 'layers.23.self_attn.query_key_value.bias', 'layers.1.self_attn.query_key_value.bias', 'layers.5.mlp.fc2.weight', 'layers.9.input_layernorm.bias', 'layers.19.mlp.fc2.bias', 'layers.15.self_attn.dense.weight', 'layers.15.self_attn.query_key_value.weight', 'layers.13.self_attn.query_key_value.bias', 'layers.2.mlp.fc2.bias', 'layers.16.mlp.fc1.bias', 'layers.0.input_layernorm.weight', 'layers.0.mlp.fc2.bias', 'layers.4.mlp.fc1.weight', 'layers.16.self_attn.query_key_value.bias', 'layers.19.mlp.fc1.weight', 'layers.22.self_attn.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_processor_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mautomatic-speech-recognition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/phi-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/transformers/pipelines/__init__.py:1070\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1068\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m-> 1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-demo-ANNCJvwW-py3.10/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py:279\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__init__\u001b[0;34m(self, model, feature_extractor, tokenizer, decoder, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING_NAMES\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq2seq\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m--> 279\u001b[0m     \u001b[43mfeature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processor_class\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m feature_extractor\u001b[38;5;241m.\u001b[39m_processor_class\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWithLM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    282\u001b[0m ):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m decoder\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctc_with_lm\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_processor_class'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-demo-ANNCJvwW-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
